{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install torchvision\n",
    "!pip3 install torch\n",
    "!pip3 install pandas\n",
    "!pip3 install matplotlib"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T07:19:45.359715Z",
     "start_time": "2024-05-13T07:19:45.284353Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autoencoders'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 17\u001B[0m\n\u001B[0;32m     13\u001B[0m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mautoencoders\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mautoencoders\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimages_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CustomImageDataset\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'autoencoders'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from autoencoders.utils import *\n",
    "from autoencoders.images_loader import CustomImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'Using device : {device}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((120, 72)),  # Resize images to 120x68\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize images\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = CustomImageDataset('/Users/vladyslavtaraban/Documents/NULP/ML/course_work/uav_geo_localisation/data/satelites/cropped_images', transform=transform)\n",
    "\n",
    "train_set, val_set, test_set = train_val_test_split(dataset, 0.2, 0.01)\n",
    "\n",
    "print(len(dataset))\n",
    "print(len(train_set) + len(val_set) + len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define residual block and autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A two-convolutional layer residual block.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, c_in, c_out, k, s=1, p=1, mode='encode'):\n",
    "        assert mode in ['encode', 'decode'], \"Mode must be either 'encode' or 'decode'.\"\n",
    "        super(ResBlock, self).__init__()\n",
    "        if mode == 'encode':\n",
    "            self.conv1 = nn.Conv2d(c_in, c_out, k, s, p)\n",
    "            self.conv2 = nn.Conv2d(c_out, c_out, 3, 1, 1)\n",
    "        elif mode == 'decode':\n",
    "            self.conv1 = nn.ConvTranspose2d(c_in, c_out, k, s, p)\n",
    "            self.conv2 = nn.ConvTranspose2d(c_out, c_out, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.BN = nn.BatchNorm2d(c_out)\n",
    "        self.resize = s > 1 or (s == 1 and p == 0) or c_out != c_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv1 = self.BN(self.conv1(x))\n",
    "        relu = self.relu(conv1)\n",
    "        conv2 = self.BN(self.conv2(relu))\n",
    "        if self.resize:\n",
    "            x = self.BN(self.conv1(x))\n",
    "        return self.relu(x + conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    \"\n",
    "    Encoder class, mainly consisting of three residual blocks.\n",
    "    \"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 48, 3, 3, 0) # 48 10 10\n",
    "        self.BN = nn.BatchNorm2d(48)\n",
    "        self.rb1 = ResBlock(48, 48, 3, 2, 1, 'encode') # 48 5 5\n",
    "        self.rb2 = ResBlock(48, 24, 3, 2, 1, 'encode') # 24 3 3\n",
    "        self.rb3 = ResBlock(24, 24, 2, 1, 0, 'encode') # 24 2 2\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        init_conv = self.relu(self.BN(self.init_conv(inputs)))\n",
    "        rb1 = self.rb1(init_conv)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        return rb3\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class, mainly consisting of three residual blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 16, 3, 1, 1)  # Output: 120 x 68\n",
    "        self.BN = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.rb1 = ResBlock(16, 32, 3, 2, 1, 'encode')  # Output: 60 x 34\n",
    "        self.rb2 = ResBlock(32, 64, 3, 2, 1, 'encode')  # Output: 30 x 17\n",
    "        self.rb3 = ResBlock(64, 128, 3, 2, 1, 'encode') # Output: 15 x 9\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.BN(self.init_conv(inputs)))\n",
    "        x = self.rb1(x)\n",
    "        x = self.rb2(x)\n",
    "        x = self.rb3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    \"\n",
    "    Decoder class, mainly consisting of two residual blocks.\n",
    "    \"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.rb1 = ResBlock(24, 48, 3, 2, 0, 'decode') # 48 5 5\n",
    "        self.rb2 = ResBlock(48, 24, 5, 3, 0, 'decode') # 24 17 17\n",
    "        self.out_conv = nn.ConvTranspose2d(24, 3, 2, 2, 1) # 3 32 32\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        relu = self.relu(inputs)\n",
    "        rb1 = self.rb1(relu)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        out_conv = self.out_conv(rb2)\n",
    "        output = self.tanh(out_conv)\n",
    "        return output\n",
    "\"\"\"\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder class, correctly adjusted for upsampling to the original size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.rb1 = ResBlock(128, 64, 2, 2, 0, 'decode') # 30 x 17\n",
    "        self.rb2 = ResBlock(64, 32, 2, 2, 0, 'decode') # 60 x 34\n",
    "        self.rb3 = ResBlock(32, 16, 2, 2, 0, 'decode') # 120 x 68\n",
    "        self.out_conv = nn.ConvTranspose2d(16, 3, 3, 1, 1) # 120 x 72\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        rb1 = self.rb1(inputs)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        out_conv = self.out_conv(rb3)\n",
    "        output = self.tanh(out_conv)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder class, combines encoder and decoder model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        num_p = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        return num_p\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters in model: {0}\".format(Autoencoder().num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ('init_lr', 'batch_size', 'weight_decay')\n",
    "parameters = OrderedDict(\n",
    "    run = [0.05, 256, 0.001],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RunManager()\n",
    "num_epochs = 2\n",
    "\n",
    "for hparams in RunBuilder.get_runs_from_params(param_names, parameters):\n",
    "\n",
    "    # Instantiate a network model\n",
    "    ae = Autoencoder()\n",
    "\n",
    "    # Construct a DataLoader object with training data\n",
    "    train_loader = DataLoader(train_set, batch_size=hparams.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=hparams.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=10, shuffle=False)\n",
    "    test_images = next(iter(test_loader))\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.SGD(ae.parameters(), lr=hparams.init_lr, momentum=0.9, weight_decay=hparams.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 60, 0.1)\n",
    "    \n",
    "    # Setup run instance\n",
    "    m.begin_run(hparams, ae, test_images)\n",
    "    print('Now training model with hyperparameters: init_lr={0}, batch_size={1}, weight_decay={2}'\n",
    "         .format(hparams.init_lr, hparams.batch_size, hparams.weight_decay))\n",
    "    \n",
    "    # Start training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        # Train the model\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            images = batch\n",
    "            \n",
    "            # Zero all gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Calculating the loss\n",
    "            preds = ae(images)\n",
    "            loss = F.mse_loss(preds, images)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                with torch.no_grad():\n",
    "                    val_images = next(iter(val_loader))\n",
    "                    val_preds = ae(val_images)\n",
    "                    val_loss = F.mse_loss(val_preds, val_images)\n",
    "                    m.track_loss(val_loss, val_images.size(0), mode='val')\n",
    "                print('Epoch {0}, iteration {1}: train loss {2}, val loss {3}'.format(epoch+1,\n",
    "                                                                               i*hparams.batch_size,\n",
    "                                                                               round(loss.item(), 6),\n",
    "                                                                               round(val_loss.item(), 6)))\n",
    "            \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss, images.size(0), mode='train')\n",
    "            \n",
    "        m.end_epoch()\n",
    "    \n",
    "    #torch.save(ae, './models/150epochs_' + str(hparams) + '.pth')\n",
    "    m.end_run()\n",
    "    print(\"Model has finished training.\\n\")\n",
    "    scheduler.step()\n",
    "    \n",
    "m.save('results_final')\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "ae = torch.load('./models/best_Run(init_lr=0.05, batch_size=256, weight_decay=0.001).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualising test images...\\n\")\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=10, shuffle=True)\n",
    "images = next(iter(test_loader))\n",
    "print(\"Original images:\")\n",
    "imgviz(images)\n",
    "print(\"Reconstructed images:\")\n",
    "with torch.no_grad():\n",
    "    preds = ae(images)\n",
    "    imgviz(preds)\n",
    "    \n",
    "# Test loss\n",
    "test_loader = DataLoader(test_set, batch_size=len(test_set))\n",
    "for i, batch in enumerate(test_loader):\n",
    "    images = batch\n",
    "    with torch.no_grad():\n",
    "        preds = ae(images)\n",
    "        loss = F.mse_loss(preds, images) # calculates the loss\n",
    "print('Test loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
